# Internet
HTTP_PROXY="china\c00627809:hwKT1986c@proxyhk.huawei.com:8080"
HTTPS_PROXY="china\c00627809:hwKT1986c@proxyhk.huawei.com:8080"
NO_PROXY="localhost,127.0.0.1"

# Resource
SPARK_DAEMON_MEMORY=8G
SPARK_DRIVER_CORES=2
SPARK_DRIVER_MEMORY=2G
SPARK_EXECUTOR_CORES=2
SPARK_EXECUTOR_MEMORY=4G

# User
AIRFLOW_UID=0
AIRFLOW_GID=0
SPARK_UID=0
SPARK_GID=0

# Home directory setup
AIRFLOW_HOME=/opt/airflow
DBT_HOME=/home/dbt
AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=10

# Credentials need to match with service postgres-airflow
AIRFLOW_POSTGRES_USER=airflow
AIRFLOW_POSTGRES_PASSWORD=airflow
AIRFLOW_POSTGRES_HOST=postgres-airflow.local
AIRFLOW_POSTGRES_PORT=5432
AIRFLOW_POSTGRES_DB=airflow

# Credentials need to match with service postgres-dbt
DBT_POSTGRES_PASSWORD=pssd
DBT_POSTGRES_USER=dbtuser
DBT_POSTGRES_DB=dbtdb
DBT_DBT_SCHEMA=dbt
DBT_DBT_RAW_DATA_SCHEMA=dbt_raw_data
DBT_POSTGRES_HOST=postgres-dbt.local
DBT_POSTGRES_PORT=5432

# Credentials need to match with service postgres-hms
HMS_POSTGRES_PASSWORD=pssd
HMS_POSTGRES_USER=hive
HMS_POSTGRES_DB=metastore
HMS_POSTGRES_HOST=postgres-hms.local
HMS_POSTGRES_PORT=5432

# Credentials for Airflow SSH Connection
DBT_SSH_HOST=dbt-service.local
DBT_SSH_PORT=22
SSH_KEY_FILE=/root/.ssh/id_rsa

# For HDFS
HDFS_DEFAULTFS_PORT=9000
HDFS_WEBUI_PORT=9870

# For HMS
HIVE_METASTORE_PORT=9083

# For Spark 
SPARK_APP=/app/spark
SHARED_WORKSPACE=/opt/workspace

SPARK_VERSION=3.3.1
HADOOP_VERSION=3.2.3
SPARK_HOME=/usr/bin/spark-${SPARK_VERSION}
SPARK_MASTER_HOST=spark-master.local
SPARK_THRIFT_HOST=spark-thrift.local
SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8082
SPARK_UI_PORT=4040
SPARK_WORKER_PORT=8080
SPARK_THRIFT_PORT=10000

# For Hadoop
HADOOP_HOME=/usr/bin/hadoop-${HADOOP_VERSION}

# Credentials for Jupyter Notebook
JUPYTER_TOKEN=welcome
NB_USER=spark
JUPYTER_UID=0
JUPYTER_GID=0

# For minio
MINIO_SERVER_HOST=minio-service.local